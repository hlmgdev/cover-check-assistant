###########################################################
# Núcleo genérico usado pelo agente (o código só lê isso)
###########################################################

# Provider ativo (apenas um valor):
# groq, ollama, microsoft, huggingface, aws, google, anthropic, openai, deepseek, grok
LLM_PROVIDER=openai  

# Credenciais / config genéricas (mudam conforme o provider escolhido)
LLM_API_KEY=sua_api_key_aqui
LLM_MODEL_NAME=llama-3.3-70b-versatile

# Parâmetros do modelo (genéricos)
MODEL_TEMPERATURE=0.1
MODEL_MAX_TOKENS=8000

# LangGraph
LANGGRAPH_MAX_ITERATIONS=10

# ==== Ajustes gerais do agente ====
AGENT_LOG_LEVEL=INFO
AGENT_PROJECT_ROOT=.                  # Diretório raiz do projeto que será analisado
AGENT_CHECKPOINT_DB=.agent_checkpoints.sqlite  # Arquivo SQLite para checkpoints do LangGraph



###########################################################
# Presets por provider (APENAS referência, código não lê)
# Use estes blocos como cola: copie os valores para as
# variáveis genéricas acima (LLM_PROVIDER / LLM_API_KEY / LLM_MODEL_NAME).
###########################################################

# ==== Preset: Groq ====
#LLM_PROVIDER=groq
#LLM_API_KEY=your-groq-key
#LLM_MODEL_NAME=llama-3.3-70b-versatile

# ==== Preset: Ollama (local) ====
#LLM_PROVIDER=ollama
#LLM_API_KEY=      # (normalmente não precisa, se Ollama estiver local)
#LLM_MODEL_NAME=llama3

# ==== Preset: Microsoft Azure ====
#LLM_PROVIDER=microsoft
#LLM_API_KEY=your-azure-api-key
#LLM_MODEL_NAME=seu-deployment-ou-model
#AZURE_ENDPOINT=your-azure-endpoint
#AZURE_API_VERSION=2024-02-15-preview

# ==== Preset: Hugging Face ====
#LLM_PROVIDER=huggingface
#LLM_API_KEY=your-hf-token
#LLM_MODEL_NAME=meta-llama/Meta-Llama-3-70B

# ==== Preset: AWS Bedrock ====
#LLM_PROVIDER=aws
#LLM_API_KEY=           # opcional, você pode usar AWS_ACCESS_KEY_ID + SECRET
#LLM_MODEL_NAME=anthropic.claude-3-sonnet-20240229-v1:0
#AWS_ACCESS_KEY_ID=your-access-key
#AWS_SECRET_ACCESS_KEY=your-secret-key
#AWS_REGION=us-east-1

# ==== Preset: Google (Gemini) ====
#LLM_PROVIDER=google
#LLM_API_KEY=your-google-key
#LLM_MODEL_NAME=gemini-1.5-flash

# ==== Preset: Anthropic (Claude) ====
#LLM_PROVIDER=anthropic
#LLM_API_KEY=your-claude-key
#LLM_MODEL_NAME=claude-3-5-sonnet

# ==== Preset: OpenAI ====
#LLM_PROVIDER=openai
#LLM_API_KEY=sua_api_key_aqui
#LLM_MODEL_NAME=gpt-4.1-mini

# ==== Preset: DeepSeek ====
#LLM_PROVIDER=deepseek
#LLM_API_KEY=your-deepseek-key
#LLM_MODEL_NAME=deepseek-chat

# ==== Preset: Grok (xAI) ====
#LLM_PROVIDER=grok
#LLM_API_KEY=your-grok-key
#LLM_MODEL_NAME=grok-2-latest

###########################################################
# ==== Ajustes gerais do agente ====
###########################################################

# Nível de verbosidade do agente (DEBUG, INFO,  WARNING,ERROR, CRITICAL)
AGENT_LOG_LEVEL=INFO

# Diretório raiz do projeto .NET que será analisado
AGENT_PROJECT_ROOT=.

# Arquivo SQLite usado pelo LangGraph para checkpointing
AGENT_CHECKPOINT_DB=.agent_checkpoints.sqlite


